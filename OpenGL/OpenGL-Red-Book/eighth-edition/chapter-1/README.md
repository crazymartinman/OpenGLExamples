# Chapter 1 - Introduction to OpenGL

### What is OpenGL?
OpenGL is an application programming interface (API), it is a software library for accessing features in graphics hardware.
In OpenGL, you must construct your three-dimensional objects from a small set of geometric primitives - points, lines, 
triangles, ang patches. OpenGL was first developed at Silicon Graphics Computer Systems with Version 1.0 released July of
1994.

The following is a list of brief operations that an OpenGL application would perform to render an image:
* Specify the data for constructing shapes from OpenGL's geometric primitives.
* Execute various shaders to perform calculations on the input primitives to determine their position, color, and other rendering attributes.
* Convert the mathematical description of the input primitives into their fragments associated with locations on the screen. This process is called rasterization.
* Finally, execute a fragment shader for each of the fragments generated by rasterization, which will determine the fragment's final color and position.
* Possibly perform additional per-fragment operations such as determining if the object that the fragment was generated from is visible, or blending the fragment's color with the current color in that screen locate.

OpenGL is implemented as a client-server system, with the applications written by developers being considered the client,
and the OpenGL implementation provided by the manufacturer of your computer graphics hardware being the server.

### Your First look at an OpenGL Program
The basic structure of all OpenGL applications is usually similar to the following:
* Initialize the state associated with how objects should be rendered.
* Specify those objects to be rendered.

Before we look at some code, we are going to introduce some graphics terminology. The term "rendering", is the process
by which a copmuter creates an image from models. OpenGL is just one example of a rendering system - OpenGL is a 
rasterization-based system, but there are other methods for generating images as well, such as ray tracing; however, 
even a system that uses ray tracing may employ OpenGL to display an image, or compute information to be used in creating
an image.

Our "models", or "objects" - we will use the terms interchangably - are constructed from geometric primitives - points,
lines, and triangles - that are specified by their vertices.

Another concept that is essential to using OpenGL is shaders, which are special functions that the graphics hardware executes.
The best way to think of shaders is as little programs that are specifically compiled for your graphics processing unit - 
commonly called a graphics processing unit (GPU). OpenGL includes all the compiler tool internally to take the source code of
your shader and create the code that the GPU needs to execute. In OpenGL, there are four shader stages that you can use. The 
most common are vertex shaders, which process vertex data, and fragment shaders, which operate on the fragments generated by
the rasterizer. Both vertex and fragment shaders are required in every OpenGL program.

The final generated image consist of pixels drawn on the screen; a pixel is the smallest visible element on your display. The
pixels in your system are stored in a framebuffer, which is a chunk of memory that the graphics hardware manages, and feeds to
your display device.

### Dissecting first example
This is just a disclaimer, the source code provided in the book was not complete and difficult to get started. I have re-written
portions of the code in order to get them working with libraries that regularly used at this particular point in time; however,
in the future it would be nice to remove these libraries and write a basic platform specific code to handle all of the setup
task. 
